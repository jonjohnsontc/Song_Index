{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# 01b_collection: Querying Spotipy for Audio Features + Analysis\n",
    "\n",
    "**Description**: Using the Spotipy wrapper, retrieving audio features and audio analysis from the Spotify API.\n",
    "\n",
    "**Disclaimer**: Since certain processes within this notebook require API keys (which are not stored within this notebook), or datbase access credentials, it is not possible to run every cell from start to finish. If you'd like to do so, you'll need to request Spotify API access with client credentials [here](https://developer.spotify.com/dashboard/login), and reach out to receive access to the SQL database referenced."
=======
    "# 01b_Collection: Querying Spotipy for Audio Features + Analysis\n",
    "\n",
    "**Description**: Using the Spotipy wrapper, retrieving audio features and audio analysis from the Spotify API.\n",
    "\n",
    "**Disclaimer**: Since certain processes within this notebook require API keys (which are not stored within this notebook), it is not possible to run every cell from start to finish. If you'd like to do so, you'll need to request Spotify API access with client credentials [here](https://developer.spotify.com/dashboard/login)."
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
<<<<<<< HEAD
    "1. [Retrieving Audio Features](#1)\n",
    "1. [Creating `master_song_list` ](#2)\n",
    "2. [Retrieving Audio Analysis](#3)"
=======
    "1. Retrieving Audio Features\n",
    "2. Retrieving Audio Analysis"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import time\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** Client Credentials are listed for illustrative purposes only. You will not be able to replicate the information contained here without actual API access credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_credentials_manager = SpotifyClientCredentials(client_id=\"xXXXXXxxxXXXXXxxxxXXXxx\",\n",
    "                                                          client_secret=\"xXXXXXxxxXXXXXxxxxXXXxx\")\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#### Loading in Song List\n",
    "\n",
    "Necessary for retrieving audio features"
=======
    "#### Testing Connection"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/song_list.pkl', 'rb+') as f:\n",
    "    df = pickle.load(f)"
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'danceability': 0.61,\n",
       "  'energy': 0.926,\n",
       "  'key': 8,\n",
       "  'loudness': -4.843,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0479,\n",
       "  'acousticness': 0.031,\n",
       "  'instrumentalness': 0.0012,\n",
       "  'liveness': 0.0821,\n",
       "  'valence': 0.861,\n",
       "  'tempo': 172.638,\n",
       "  'type': 'audio_features',\n",
       "  'id': '62bOmKYxYg7dhrC6gH9vFn',\n",
       "  'uri': 'spotify:track:62bOmKYxYg7dhrC6gH9vFn',\n",
       "  'track_href': 'https://api.spotify.com/v1/tracks/62bOmKYxYg7dhrC6gH9vFn',\n",
       "  'analysis_url': 'https://api.spotify.com/v1/audio-analysis/62bOmKYxYg7dhrC6gH9vFn',\n",
       "  'duration_ms': 200400,\n",
       "  'time_signature': 4}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.audio_features('62bOmKYxYg7dhrC6gH9vFn')"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "<a name=\"1\"></a>\n",
    "## 1. Retrieving Audio Features"
=======
    "### 1. Retrieving Audio Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading in Song List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/song_list.pkl', 'rb+') as f:\n",
    "    song_list = pickle.load(f)"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### 1a. Retrieving Audio Features for Every Song in `song_list`\n",
=======
    "#### 1a. Retrieving Audio Features for Every Song in `song_list`\n",
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
    "\n",
    "Adding `try` & `except` statements, along with `sleep` times was necessary to keep audio feature extraction going uninterrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_feat = []\n",
    "\n",
    "for i in song_list:\n",
    "    if isinstance(i, dict):\n",
    "        id_list = []\n",
    "        for k in i['tracks']:\n",
    "            id_list.append(k['id'])\n",
    "    else:\n",
    "        continue\n",
    "    try:\n",
    "        song_feat.append(sp.audio_features(id_list))\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        time.sleep(5)\n",
    "        song_feat.append(sp.audio_features(id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2444"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(song_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/song_feat.pkl', 'wb+') as f:\n",
    "    pickle.dump(song_feat, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "<a name=\"2\"></a>\n",
    "## 2. Creating Master Song List\n",
    "\n",
    "This will eventually become the X array for recommendations. For the time being, it's necessary for checking progress on retrieving audio analysis files.\n"
=======
    "#### Retrieving Audio Analysis for Every Song in `song_list`\n",
    "\n",
    "I'll break this up in batches, just to make sure I don't overload the RAM:"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bye Bye Bye'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_list[0]['tracks'][0]['name']"
=======
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bye Bye Bye': '62bOmKYxYg7dhrC6gH9vFn'}\n",
      "{'This I Promise You': '46n2EGFnPC3tzWCN1Aqe26'}\n",
      "{\"It's Gonna Be Me\": '2AW37v0bDyuOzGP3XnmFuA'}\n"
     ]
    }
   ],
   "source": [
    "for i in master_song_list[:3]:\n",
    "    for k, v in i.items():"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_song_list = []\n",
    "\n",
    "for entry in song_list:\n",
    "    if isinstance(entry, dict):\n",
    "        for track in entry['tracks']:\n",
    "            master_song_list.append(dict({track['name'] : track['id']}))"
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# song_list[764]"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/master_song_list.json', 'r') as f:\n",
    "    master_song_list = json.load(f)"
=======
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in song_list[1500:]:\n",
    "    if isinstance(i, dict):\n",
    "        for k in i['tracks']:\n",
    "            try:\n",
    "                analysis = sp.audio_analysis(k['id'])\n",
    "            except:\n",
    "                time.sleep(5)\n",
    "                analysis = sp.audio_analysis(k['id'])\n",
    "            with open('../data/audio_analysis/{}.json'.format(k['id']), 'w') as f:\n",
    "                json.dump(analysis, f)"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "##### Size of `master_song_list`"
=======
    "#### Checking to See Which Songs Weren't Grabbed in Audio Analysis"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/analysis_list.txt', delimiter=\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: x.str.rstrip('.json'), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "23888"
      ]
     },
     "execution_count": 7,
=======
       "(23129, 1)"
      ]
     },
     "execution_count": 82,
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "len(master_song_list)"
=======
    "df.shape"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 64,
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "9626864"
      ]
     },
     "execution_count": 8,
=======
       "<sqlalchemy.engine.base.Connection at 0x7fa6daec65f8>"
      ]
     },
     "execution_count": 64,
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "23888 * 403"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dumping Master Song List to `.json`"
=======
    "engine = create_engine('postgresql://postgres:glide-mortuary-pod-cloy-belong@ec2-54-244-70-11.us-west-2.compute.amazonaws.com:5432/postgres')\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_id_list = pd.read_sql(\"\"\"\n",
    "                            SELECT * FROM song_list\n",
    "                            \"\"\", con=engine)"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/master_song_list.json', 'w+') as f:\n",
    "    json.dump(master_song_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3. Retrieving Audio Analysis for Every Song in `song_list`\n",
    "\n",
    "Due to the size of a combined resulting dict, I saved every song's corresponding audio analysis into a separate json file. This made it easier to eventually load in, perform EDA, and manipulate, as I could do it on a single song basis (the total size of audio analysis files utilized is roughly 10GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in song_list:\n",
    "    if isinstance(i, dict):\n",
    "        for k in i['tracks']:\n",
    "            try:\n",
    "                analysis = sp.audio_analysis(k['id'])\n",
    "            except:\n",
    "                time.sleep(5)\n",
    "                analysis = sp.audio_analysis(k['id'])\n",
    "            with open('../data/audio_analysis/{}.json'.format(k['id']), 'w') as f:\n",
    "                json.dump(analysis, f)"
=======
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_aa = song_id_list[~song_id_list['song_id'].isin(df[0])]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1506, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_aa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like 1506 titles weren't reterieved in the Audio Analysis API pull. Further, some of the .json's that I did pull don't seem to have the same feature set, wherein certain features (like `rhythmstring`) are note included."
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#### Checking to See Which Songs Weren't Grabbed in Audio Analysis"
=======
    "#### Creating Array of Song Titles + Unique ID\n",
    "\n",
    "I'll need this for a ton of different things, including checking my progress on grabbing the audio analysis."
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/analysis_list.txt', delimiter=\" \", header=None)"
=======
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bye Bye Bye'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_list[0]['tracks'][0]['name']"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: x.str.rstrip('.json'), 1)"
=======
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_song_list = []\n",
    "\n",
    "for entry in song_list:\n",
    "    if isinstance(entry, dict):\n",
    "        for track in entry['tracks']:\n",
    "            master_song_list.append(dict({track['name'] : track['id']}))"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23129, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
=======
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/master_song_list.json', 'r') as f:\n",
    "    master_song_list = json.load(f)"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#### Connecting to PostgreSQL to Retreive Song Listing\n",
    "\n",
    "For ease of access anywhere, I established a PostgreSQL database, where I've been storing all of the tables created during the data collection process.\n",
    "\n",
    "**Disclaimer**: The credentials listed are for illustrative purposes only. Please reach out if you'd like to connect to this database."
=======
    "##### Size of `master_song_list`"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 64,
=======
   "execution_count": 7,
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "<sqlalchemy.engine.base.Connection at 0x7fa6daec65f8>"
      ]
     },
     "execution_count": 64,
=======
       "23888"
      ]
     },
     "execution_count": 7,
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "engine = create_engine('postgresql://xxxXXXXXXxxxXXXxxxxxx:xxxXXXXXXxxxxxxxXXXxxxxxx@xxxXXXXXXxxxx:5432/xxxXXXXXXxxxXXXxx')\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_id_list = pd.read_sql(\"\"\"\n",
    "                            SELECT * FROM song_list\n",
    "                            \"\"\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_aa = song_id_list[~song_id_list['song_id'].isin(df[0])]    "
=======
    "len(master_song_list)"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 85,
=======
   "execution_count": 8,
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(1506, 2)"
      ]
     },
     "execution_count": 85,
=======
       "9626864"
      ]
     },
     "execution_count": 8,
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "no_aa.shape"
=======
    "23888 * 403"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Looks like 1506 titles weren't reterieved in the Audio Analysis API pull. However, I did not consider this a large enough amount to stop processing and grab additional songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next notebook: 02_cleaning"
=======
    "##### Dumping Master Song List to `.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/master_song_list.json', 'w+') as f:\n",
    "    json.dump(master_song_list, f)"
>>>>>>> cb481816e2e759248d8174f714dfa3ef3b218aa4
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
