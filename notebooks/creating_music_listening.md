from: http://web.media.mit.edu/~tristan/phd/dissertation/index.html

# Creating Music by Listening (2005)

## 2. Background

### AI approaches to Automated Composition:
- David Cope's Experiments in Musical Intelligence (EMI)
- Francois Pachet's Continuator

### Framework:
- > The mechanism applies well to the modification of audio signals in general, but is generally blind regarding the embedded musical content. We introduce an extension of the sound analysis/resynthesis principle for music (Figure 2-2). Readily, our music-aware analysis/resynthesis approach enables higher-level transformations independently of the sound content, including beat matching, music morphing, music cross-synthesis, music similarities.

### Description:
- In auditory scene analysis, by which humans build mental descriptions of complex auditory environments, abrupt events represent important sound source-separation cues.
  - We chose to first detect sound events and segment the audio in order to facilitate its analysis, and refine the description of music. **This is going to be the recurrent theme throughout this document.

## 3. Music Listening


